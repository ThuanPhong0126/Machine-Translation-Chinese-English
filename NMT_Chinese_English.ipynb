{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSsseBKu0NbOt84E3HyysW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThuanPhong0126/Machine-Translation-Chinese-English/blob/main/NMT_Chinese_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wnO1xHgLuaJ",
        "outputId": "024df845-d8cd-4de6-99cd-e93b6b330081"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQTJUocCL-Pc",
        "outputId": "44bbba3b-da1a-432c-ccd2-131b65e81a53"
      },
      "source": [
        "cd /content/drive/MyDrive/Machine_Translation"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Machine_Translation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMvl1lg6MyyB"
      },
      "source": [
        "Encoder-Decoder Architecture\n",
        "\n",
        "![Encoder-Decoder Architecture](https://nthu-datalab.github.io/ml/labs/13-1_Seq2Seq-Learning_Neural-Machine-Translation/imgs/encoder_to_decoder.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNoJQz5eMVeE"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pylab import *\n",
        "from matplotlib.font_manager import FontProperties"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovh39NefN33t",
        "outputId": "6a41c332-a933-4455-b3f9-2897d87c58c9"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs, \", len(logical_gpus), \"logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    print(e)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs,  1 logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95H2hko6Ov4V"
      },
      "source": [
        "path_dataset = \"./cmn.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvDNXV53TP7U"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiCp2wgnPODS"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\n",
        "\n",
        "def preprocess_eng(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "  #Python padding punctuation with white spaces keeping punctuation\n",
        "  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
        "  #Replace several spaces with one spaces\n",
        "  w = re.sub(r'[\" \"]+',\" \",w)\n",
        "  #replacing everythong with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n",
        "  w = w.rstrip().strip()\n",
        "  w = '<start> '+w+' <end>'\n",
        "  return w\n",
        "\n",
        "def preprocess_chinese(w):\n",
        "  w= unicode_to_ascii(w.lower().strip())\n",
        "  w = re.sub(r'[\" \"]+', \"\", w)\n",
        "  w = w.rstrip().strip()\n",
        "  w = \" \".join(list(w))\n",
        "  w = '<start> '+w+' <end>'\n",
        "  return w"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHjGy_FvRVS2",
        "outputId": "756566af-caf0-4d63-aaff-243be51f22d7"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "chn_sentence = u\"我可以借這本書麼？\"\n",
        "print(preprocess_eng(en_sentence))\n",
        "print(preprocess_chinese(chn_sentence))\n",
        "print(preprocess_chinese(chn_sentence).encode('utf-8'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "<start> 我 可 以 借 這 本 書 麼 ？ <end>\n",
            "b'<start> \\xe6\\x88\\x91 \\xe5\\x8f\\xaf \\xe4\\xbb\\xa5 \\xe5\\x80\\x9f \\xe9\\x80\\x99 \\xe6\\x9c\\xac \\xe6\\x9b\\xb8 \\xe9\\xba\\xbc \\xef\\xbc\\x9f <end>'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtPoJv-eRYhI",
        "outputId": "2ecbaf38-c24a-4998-affb-684f62b3e7b8"
      },
      "source": [
        "def create_dataset(path_dataset, num_examples=None):\n",
        "  lines = open(path_dataset, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[w for w in l.split('\\t')[:2]] for l in lines]\n",
        "  word_pairs = [[preprocess_eng(w[0]), preprocess_chinese(w[1])] for w in word_pairs]\n",
        "  return word_pairs\n",
        "\n",
        "word_pairs = create_dataset(path_dataset)\n",
        "word_pairs[50:60]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<start> he runs . <end>', '<start> 他 跑 。 <end>'],\n",
              " ['<start> help me . <end>', '<start> 帮 我 一 下 。 <end>'],\n",
              " ['<start> help us . <end>', '<start> 帮 帮 我 们 吧 ！ <end>'],\n",
              " ['<start> hit tom . <end>', '<start> 去 打 汤 姆 。 <end>'],\n",
              " ['<start> hold on . <end>', '<start> 坚 持 。 <end>'],\n",
              " ['<start> hug tom . <end>', '<start> 抱 抱 汤 姆 ！ <end>'],\n",
              " ['<start> hug tom . <end>', '<start> 请 抱 紧 汤 姆 。 <end>'],\n",
              " ['<start> i agree . <end>', '<start> 我 同 意 。 <end>'],\n",
              " ['<start> i m ill . <end>', '<start> 我 生 病 了 。 <end>'],\n",
              " ['<start> i m sad . <end>', '<start> 我 很 难 过 。 <end>']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-JUt9BKTFSI",
        "outputId": "b4f2aa3e-085a-4107-a039-30966952e239"
      },
      "source": [
        "en, ch = zip(*create_dataset(path_dataset))\n",
        "print(en[-1])\n",
        "print(ch[-1])\n",
        "assert len(en)==len(ch)\n",
        "print(\"Size: \", len(en))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language . <end>\n",
            "<start> 如 果 一 個 人 在 成 人 前 沒 有 機 會 習 得 目 標 語 言 ， 他 對 該 語 言 的 認 識 達 到 母 語 者 程 度 的 機 會 是 相 當 小 的 。 <end>\n",
            "Size:  26388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-cWGa8TrQD"
      },
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)\n",
        "\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  #generate a dictionary\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  #output the vector sequences\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  #padding sentences to the same length\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "  return tensor, lang_tokenizer\n",
        "\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  # regard Chinese as source sentence, regard English as target sentence\n",
        "  target_lang, input_lang = zip(*create_dataset(path_dataset, num_examples))\n",
        "  input_tensor, input_lang_tokenizer = tokenize(input_lang)\n",
        "  target_tensor, target_lang_tokenizer = tokenize(target_lang)\n",
        "  return input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVUM9wmWXq5e",
        "outputId": "5f9b503c-ce2d-448a-d313-c6eb64b1afe9"
      },
      "source": [
        "num_examples = 15000\n",
        "input_tensor, target_tensor, input_lang, target_lang = load_dataset(path_dataset, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "#Creating training and validation sets\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(\n",
        "    input_tensor, target_tensor, test_size = 0.1\n",
        ")\n",
        "\n",
        "print(f\"Training data: {len(input_tensor_train)}\\nTest data: {len(input_tensor_val)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data: 23749\n",
            "Test data: 2639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71Ett-rFZAT-",
        "outputId": "fcb123b5-5bfa-468e-d73d-1aeffc94b02f"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t != 0:\n",
        "      print(f\"{t} ----> {lang.index_word[t]}\")\n",
        "\n",
        "print(\"Input Language; index to word mapping\")\n",
        "convert(input_lang, input_tensor_train[0])\n",
        "print()\n",
        "print(\"Target language; index to word mapping\")\n",
        "convert(target_lang, target_tensor_train[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "7 ----> 你\n",
            "26 ----> 們\n",
            "13 ----> 在\n",
            "513 ----> 哭\n",
            "40 ----> 嗎\n",
            "11 ----> ？\n",
            "2 ----> <end>\n",
            "\n",
            "Target language; index to word mapping\n",
            "1 ----> <start>\n",
            "31 ----> are\n",
            "7 ----> you\n",
            "759 ----> guys\n",
            "692 ----> crying\n",
            "9 ----> ?\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Lu75yMbNMr"
      },
      "source": [
        "### Create a tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2aGj053aWZT",
        "outputId": "ba64b3f1-3cf0-4c22-cfa4-2a904192b9b6"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 128\n",
        "steps_per_epochs = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_input_size = len(input_lang.word_index)+1\n",
        "vocab_target_size = len(target_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 46]), TensorShape([128, 38]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbL_SCkOdPWO"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwwSvpn2cb5l"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True, \n",
        "                                   return_state = True,\n",
        "                                   recurrent_activation='sigmoid',\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "  def call(self,x , hidden):\n",
        "    #after embedding, x.shape==(batch_size, max_length, embedding_dim)->(128,46,256)\n",
        "    x = self.embedding(x)\n",
        "    #output shape==(batch_size, max length, units)->(128, 46, 1024)\n",
        "    #state is the hidde state of the last timestamp, shape=(batch_size, units)->(128,1024)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gJwsjq_hGgt",
        "outputId": "0280c2d3-2b1a-4eed-a453-b5e37b38e5b0"
      },
      "source": [
        "encoder = Encoder(vocab_input_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "#Sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print('Encoder output shape: ', sample_output.shape)\n",
        "print('Encoder hidden state shape: ', sample_hidden.shape)\n",
        "\n",
        "# the output and the hidden state of GRU is equal\n",
        "print(sample_output[-1, -1, :] == sample_hidden[-1, :])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape:  (128, 46, 1024)\n",
            "Encoder hidden state shape:  (128, 1024)\n",
            "tf.Tensor([ True  True  True ...  True  True  True], shape=(1024,), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENwulS6GiY6t"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWhGX3doiRtw"
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    #query shape == (batch size, hidden size)\n",
        "    #hidden with time axis shape == (batch size,1, hidden size)\n",
        "    #i am doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    #score shape == (batch size, max length, 1)\n",
        "    #we get 1 at the last axis bacause we are applying score to self.V\n",
        "    #the shape of the tensor before applying self.V is (batch size, max length, units)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    #attention weights shape == (batch size, max length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    #context vector shape == (batch size, max length, hidden size)\n",
        "    context_vector = attention_weights * values\n",
        "\n",
        "    #context vector shape after sum == (batch size, hidden size)\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLJ0EjkXk19d",
        "outputId": "122fad54-dd38-4ccf-b620-ecd95dd70e42"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (128, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (128, 46, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss9rHzXBpaEf"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXw5zS6MlJbZ"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    # the dimension of the output is the vocab size, through the softmax function,\n",
        "    # this layer will return the probability of each word in the dictory\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    #used for anttention\n",
        "    self.attention = BahdanauAttention(vocab_size)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    #This function outputs a result at each timestamp\n",
        "    #The hidden state of first timestamp in the decoder is the hidden state of last timestamp in the encoder\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    #x shape after passing through embedding == (batch size, 1, embedding dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    #concatenate the input x and the context vector, as the input of the GRU\n",
        "    #context vector shape==(batch size, units)->(128, 1024)\n",
        "    #x shape after concatenation==(batch size, 1, embedding dim+hidden size)->(128,1,1024+256)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    # get the output and state of the current timestamp\n",
        "    # output shape == (batch_size, 1, units) -> (128, 1, 1024) \n",
        "    # state shape == (batch_size, units) -> (128, 1024)\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    #output shape == (batch size, hidden size)->(128, 1024)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    #output shape==(batch size, vocab)->(128, 6082)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J4jPUL41qM_",
        "outputId": "38e5ed94-b270-4c81-9197-00b4ea629c1d"
      },
      "source": [
        "decoder = Decoder(vocab_target_size, embedding_dim, units, BATCH_SIZE)\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
        "print('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (128, 6755)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nibj6vOZmvAG"
      },
      "source": [
        "### Define the optimizer and the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp_awSHw11Oo"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqwZS0UCnu4f"
      },
      "source": [
        "checkpoint_dir = \"./checkpoints/chinese-eng\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfYak6uSpdKh"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    #feed the <start> as the input of the decoder\n",
        "    #dec input shape == (batch size, 1)->(128, 1)\n",
        "    dec_input  =tf.expand_dims([target_lang.word_index['<start>']]*BATCH_SIZE,1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    # because of the data preprocessing(add a start token to the sentence)\n",
        "    # the first word is <start>, so t starts from 1(not 0)\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      # targ[:, t] is the true label(index of the word) of every sentence(in a batch) \n",
        "      # at the current timestamp\n",
        "      # like [  85   18   25   25  ···  1047   79   13], shape == (batch_size,) -> (128,)\n",
        "      # predictions shape == (batch_size, vocab_size) -> (128, 6082)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    #collect all trainable variables\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    #calculate the gradients for the whole variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    #apply the gradients on the variables\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdS4bCfBsqHj",
        "outputId": "654570a7-6ad9-4bef-f88c-feb0a44dd4af"
      },
      "source": [
        "EPOCHS = 25\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  #get the initial hidden state of gru\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epochs)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch_loss%100==0:\n",
        "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy()}')\n",
        "\n",
        "  #saving checkpoint the model every 5 epocs\n",
        "  if (epoch+1)%5==0:\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epochs}')\n",
        "  print(f'time taken for 1 epoch {time.time()-start}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.1043102741241455\n",
            "time taken for 1 epoch 333.83062839508057\n",
            "Epoch 2 Loss 0.8416135907173157\n",
            "time taken for 1 epoch 296.1163806915283\n",
            "Epoch 3 Loss 0.7129939794540405\n",
            "time taken for 1 epoch 296.3932695388794\n",
            "Epoch 4 Loss 0.6042443513870239\n",
            "time taken for 1 epoch 296.49609756469727\n",
            "Epoch 5 Loss 0.5030615925788879\n",
            "time taken for 1 epoch 298.59099864959717\n",
            "Epoch 6 Loss 0.41558945178985596\n",
            "time taken for 1 epoch 296.56155133247375\n",
            "Epoch 7 Loss 0.339623361825943\n",
            "time taken for 1 epoch 296.52263140678406\n",
            "Epoch 8 Loss 0.27388593554496765\n",
            "time taken for 1 epoch 296.4712345600128\n",
            "Epoch 9 Loss 0.21988479793071747\n",
            "time taken for 1 epoch 296.4626166820526\n",
            "Epoch 10 Loss 0.17386150360107422\n",
            "time taken for 1 epoch 298.2659709453583\n",
            "Epoch 11 Loss 0.13810282945632935\n",
            "time taken for 1 epoch 296.4075005054474\n",
            "Epoch 12 Loss 0.11114412546157837\n",
            "time taken for 1 epoch 296.42931604385376\n",
            "Epoch 13 Loss 0.0871957391500473\n",
            "time taken for 1 epoch 296.38758158683777\n",
            "Epoch 14 Loss 0.06751136481761932\n",
            "time taken for 1 epoch 296.345986366272\n",
            "Epoch 15 Loss 0.05408704653382301\n",
            "time taken for 1 epoch 298.4669647216797\n",
            "Epoch 16 Loss 0.044149186462163925\n",
            "time taken for 1 epoch 296.4625446796417\n",
            "Epoch 17 Loss 0.039111848920583725\n",
            "time taken for 1 epoch 296.4436573982239\n",
            "Epoch 18 Loss 0.03526785224676132\n",
            "time taken for 1 epoch 296.44602823257446\n",
            "Epoch 19 Loss 0.033726613968610764\n",
            "time taken for 1 epoch 296.3199260234833\n",
            "Epoch 20 Loss 0.032392263412475586\n",
            "time taken for 1 epoch 297.8742341995239\n",
            "Epoch 21 Loss 0.0300001110881567\n",
            "time taken for 1 epoch 296.45089197158813\n",
            "Epoch 22 Loss 0.026556268334388733\n",
            "time taken for 1 epoch 296.37048411369324\n",
            "Epoch 23 Loss 0.02470788173377514\n",
            "time taken for 1 epoch 296.3044652938843\n",
            "Epoch 24 Loss 0.023125633597373962\n",
            "time taken for 1 epoch 296.28900504112244\n",
            "Epoch 25 Loss 0.023114949464797974\n",
            "time taken for 1 epoch 297.87965989112854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxznztgPt66m"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  #max length target 38, max length input 64\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  sentence = preprocess_chinese(sentence)\n",
        "\n",
        "  #convert each word to the index in the test sentence\n",
        "  inputs = [input_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  \n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  result = ''\n",
        "\n",
        "  #hidden shape==(1, 1024)\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "\n",
        "  # enc out shape == (1, max_length_inp, 1024) -> (1, 46, 1024)\n",
        "  # enc hidden shape == (1, 1024)\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([target_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "    #storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    #get the index which has the highest probability\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    #convert the index to the word\n",
        "    result += target_lang.index_word[predicted_id]+' '\n",
        "\n",
        "    #when the decoder predict the end, stop prediction\n",
        "    if target_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    #the predict id is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  # you need to change the fname based on your system, and the Chinese can be displayed in the plot\n",
        "  font = FontProperties(fname=r\"./TaipeiSansTCBeta-Regular.ttf\", size=14)\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  # set the x-tick/y-tick labels with list of string labels\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, fontproperties=font)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict, fontproperties=font)\n",
        "\n",
        "  # set tick locators\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  plt.show()\n",
        "\n",
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXH3iZGUXZ3G"
      },
      "source": [
        "### Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2915TuHDXWHj",
        "outputId": "719d9a59-7ac9-4b9c-b9b3-7562f6e3b889"
      },
      "source": [
        "checkpoint_dir = './checkpoints/chinese-eng'\n",
        "print(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./checkpoints/chinese-eng/ckpt-5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efec7757150>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "mv541LhYXq8P",
        "outputId": "3e334538-1793-4cee-f408-9d3e8ec07262"
      },
      "source": [
        "translate('你今晚會去派對嗎?')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> 你 今 晚 會 去 派 對 嗎 ? <end>\n",
            "Predicted translation: will you go to the party tonight ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "bwGhEPFbYK83",
        "outputId": "ce349483-d228-4f04-cb8a-75c7d4f182a4"
      },
      "source": [
        "translate('她明年會去美國嗎?')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> 她 明 年 會 去 美 國 嗎 ? <end>\n",
            "Predicted translation: will she go to america next year ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRnudiY_2dTy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}